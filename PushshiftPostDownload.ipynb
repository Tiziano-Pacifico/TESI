{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "accb066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime as dt            \n",
    "import pandas as pd                      \n",
    "import praw\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\CodeTesi\")\n",
    "import credential\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d8d32",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "Il primo passo è stato quello di estarre l'insieme delle submissions dall'api di pushshift in modo da avere una struttura dati snella di base contenente 3 informazioni:\n",
    "SUBMISSION ID // UTC // UTC_STR\n",
    "L'insieme delle submission ottenute tramite pushshift offre la maggior sicurezza di aver recuperato il maggior numero di esse attingendo ad un serbatoio che colleziona tutti i post di reddit.\n",
    "Questo dataframe molto semplice verrà utilizato come base per tutte le future estrazioni.\n",
    "Infatti l'api di reddit seppur più lentamente e con alcune restrizioni fornisce informazioni più dettagliate e aggiornate sui singoli oggetti.\n",
    "Tecnicamente abbiamo inserito in un loop con un valore di 1000 iterazioni la chiamata alla api di pushshift. La chiamata è stata effettuata direttamente dall'api senza wrapper. Questo metodo in genere garantisce il migliore risultato in termini di tempo e di numero di dati trovati.\n",
    "Ogni chiamata può ritornare al massimo 1000 elementi. Il numero di 1000 iterazioni su 1000 elementi da un valore massimo di 100000 di submission ritornate. LE submissions sono restituite in ordine cronologico inverso dalla più recente alla più datata. L'ultima submission ottenuta da una chiamata fornirà quindi una soglia di partenza per la prossima chiamata. \n",
    "Le submissions ottenute sono inferiori alle 100000 quindi il numero di 1000 iterazioni si è dimostrato molto superiore rispetto alle necessità.\n",
    "Inoltre ogni singola chiamata non restituisce mai il numero di 1000 risposte. Il motivo di questo comportamento potrebbe essere dovuto al fallimento di alcuni thread di ricerca e potrebbe comportare la perdita di alcune submissions.\n",
    "Il miss rate è comunque in genere inferiore al 5% e possiamo riterere il risultato ottenuto soddisfacente.\n",
    "I dati estratti sono stati restituiti come lista di tuple. Ogni elemento della tupla è relativo ad una colonna del dataframe.\n",
    "Il passaggio dalla lista al dataframe è stato effettuato iterativamente.\n",
    "Il sistema di inserimento iterativo in un dataframe è però un processo lungo che rallenta proporzionalmente alle dimension del dataframe. Nei successivi passaggi si preferirà una soluzione differente che permette una maggiore effcienza.\n",
    "Per via della modalita estrattiva il dataframe presenta alcuni duplicati. Infatti ogni nuova riciesta parte dalla data utc del messaggio più datato della richiesta precendente e aggiunge qualche secondo creando un piccolo accavallamento temporale che porta in alcuni casi a scaricare gli stessi messaggi.\n",
    "I messaggi inizialmente scaricati sono stati 74942 mentre eliminando i duplicati sulla base dell'id della submission abbiamo ottenuto un dataset di 73943 elementi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5981c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id','utc','utc_datetime_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fec5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&before={}&size={}'\n",
    "subreddit = 'ChatGPT'\n",
    "before = datetime.now()\n",
    "size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9339814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = int(before.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59d35cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = BASE_URL.format(subreddit, epoch, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c2e09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fbae497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id_utc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "59bfd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    res = (requests.get(uri)).json()['data']\n",
    "    list_id_utc.extend(list(map(lambda post: (post['id'],post['created_utc'], post['utc_datetime_str']), res)))\n",
    "    epoch = list_id_utc[-1][1] + 1\n",
    "    uri =  BASE_URL.format(subreddit, epoch, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d0d2a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74942"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_id_utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b7224",
   "metadata": {},
   "source": [
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "af1787bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_utc = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "263e80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in list_id_utc:\n",
    "    row[cols[0]] = submission[0]\n",
    "    row[cols[1]] = submission[1]\n",
    "    row[cols[2]] = submission[2]\n",
    "    df_id_utc.loc[len(df_id_utc)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5830a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74942 entries, 0 to 74941\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                74942 non-null  object\n",
      " 1   utc               74942 non-null  int64 \n",
      " 2   utc_datetime_str  74942 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_id_utc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9b132a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_utc =  df_id_utc.drop_duplicates(subset='id', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "125a89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_utc.to_json('C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\TESI\\\\RedditDS\\\\id_utc.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a48e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
