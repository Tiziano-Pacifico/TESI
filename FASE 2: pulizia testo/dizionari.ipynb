{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f440f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import sys\n",
    "!{sys.executable} - m pip install pyspellchecker\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\TESI\\\\FASE 2 Pulizia Testo\\\\Dizionari')\n",
    "import csv\n",
    "from spellchecker import SpellChecker\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\TESI\\\\FASE 2 Pulizia Testo\\\\Dizionari\\\\twitter_hash_merged.json\"\n",
    "hash_dict = pd.read_json(path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e17bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulizia hashtags\n",
    "#Rimuovo gli hashtag con frequenza minore di 100\n",
    "#Rimuovo gli hashtag che non hanno caratteri alfanumerici\n",
    "#controllo se negli hastah ci siano parole sconosciute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddd3a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = list(hash_dict['terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "979d6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_dict = hash_dict.drop(hash_dict[hash_dict['frequency'] < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64d86b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = hash_dict['terms'].str.isalnum()\n",
    "hash_dict = hash_dict[filter.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a1c403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5418bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sconosciute_hash = list(spell.unknown(hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f65e88a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sconosciute_hash) #Gli hashtag hanno molte parole sconosciute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "463d1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acronimi = [\"gan\",\"vae\",\"lstm\",\"cnn\",\"rl\",\"dcgan\",\"gpt\",\"t5\",\"bert\",\"gshard\",\"ctrl\",\"llm\",\"nlp\",\"rnn\",\"vae\",\"ner\",\"xai\",\"drl\",\"mle\"]\n",
    "Keywords = [\"language model\",\"generative model\",\"transformers\",\"pre-training\",\"pretraining\",\"fine-tuning\",\"finetuning\",\"neural networks\",\n",
    "           \"deep learning\",\" natural language processing\",\"recurrent neural networks\",\"convolutional neural networks\",\"autoencoders\",\n",
    "           \"variational autoencoders\",\"generative adversaria networks\",\"attention mechanism\",\"transfer learning\",\"multimodal learning\",\n",
    "           \"unsupervised learning\",\"reinforcement learning\",\"text generation\",\"image generation\",\"style transfer\",\"language translation\",\n",
    "           \"text classification\",\"sentiment analysis\",\"named entity recognition\",\"knoweledge graph\",\"synthetic data generation\",\n",
    "           \"explainable ai\",\"bias in ai\",\"ethic\",\"generative pretrained transformer\",\"transformer\",\"recurrent neural network\",\"autoencoder\",\n",
    "           \"variational autoencoder\",\"deep reinforcement learning\",\"maximun likelihood estimation\",\"computer vision\",\"image captioning\",\n",
    "           \"speech synthesis\",\"dialogue generation\",\"text to speach\",\"voice cloning\",\"conditional generation\",\"meta learning\",\"federated learning\"]\n",
    "persone = [\"ian goodfellow\",\"yoshua bengio\",\"geoffrey hinton\",\"andrej karpathy\",\"david ha\",\"alex krizhevsky\",\"pieter abbeel\",\"ilya sutskever\",\"samin winiger\",\n",
    "          \"ziad obermeyer\",\"satya nadella\",\"ginni rometty\",\"jeff dean\",\"yann lecun15\",\"demis hassabis\",\"noam chomsky\",\"elon musk\",\"fei fei li\",\n",
    "          \"timnit gebru\",\"john iannandrea\",\"mark zuckerberg\",\"andrew ng\",\"gary vaynerchuk\",\"ex fridman\",\"stephen fry\",\"tim ferriss\",\n",
    "          \"richard dawkins\",\"jimmy wales\",\"will smith\",\"sundar pichai\",\"demish assabis\",\"kai fu lee\",\"yoshua bengio\",\"rodney brooks\",\n",
    "          \"jeff dean\",\"reid hoffman\",\"peter thiel\",\"vinod khosla\",\"sndrew ng\",\"marc andreessen\",\"tony fadell\",\"pierre omidyar\",\n",
    "          \"richard branson\",\"jack ma\",\"eric schmidt\",\"brian eno\",\"imogen heap\",\"taryn southern\",\"holly herndon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7f3f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controllo se non ci siano parole scoonsciute negli acronimi perchè non vengano cancellate\n",
    "sconosciute_acronimi = list(spell.unknown(Acronimi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc856483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sconosciute_acronimi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72e30e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controllo se non ci siano parole scoonsciute negli keywords perchè non vengano cancellate\n",
    "sconosciute_keywords = list(spell.unknown(Keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98957883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sconosciute_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa8c6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controllo se non ci siano parole scoonsciute negli keywords perchè non vengano cancellate\n",
    "sconosciute_persone = list(spell.unknown(persone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8252b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sconosciute_persone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388a2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e54a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifico che non ci siano parole nelle stopwords che vengano rimosse ma che siano nelle liste delle parole utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64568cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in Acronimi:\n",
    "    if a in l:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29d01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in Keywords:\n",
    "    if k in l:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85de0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in hashtag:\n",
    "    if h in l:\n",
    "        print(h)\n",
    "\n",
    "#Gli hashtag di twitter contengono alcune parole in comune con le stopwords ma l'analisi delle parole in comune rivela che queste nonsono di alcun interesse ai fini delll'analisi \n",
    "#di NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfbea164",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('acronimi.csv','w') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(Acronimi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62cd857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keywords.csv','w') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31cd4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persone.csv','w') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(persone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0421d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuovo gli hashtag con caratteri giapponesi\n",
    "result = hash_dict['terms'].str.contains(pat = '[\\u30A0-\\u30FF]', regex = True)\n",
    "hash_dict1 = hash_dict[~result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b483222",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hash_dict1['terms'].str.contains(pat = '[\\u4300-\\u9faf]', regex = True)\n",
    "hash_dict2 = hash_dict1[~result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6ee7c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hash_dict2['terms'].str.isalpha()\n",
    "hash_dict3 = hash_dict2[~result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ecd5cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = list(hash_dict3['terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "894040a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hashtag.csv','w') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004b940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
