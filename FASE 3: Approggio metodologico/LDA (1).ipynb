{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\Applicativi personali\\\\Test LDA,keybert,bertopic\\\\Outputs\\\\\"\n",
    "filename = \"Articles_DF.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path+filename,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tiziano\n",
      "[nltk_data]     Pacifico\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Tiziano\n",
      "[nltk_data]     Pacifico\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Articoli preprocessati'] = df['Articolo'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articolo</th>\n",
       "      <th>Argomento</th>\n",
       "      <th>Descrizione</th>\n",
       "      <th>Articoli preprocessati</th>\n",
       "      <th>Articolo_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pop culture, short for popular culture, refers...</td>\n",
       "      <td>The Influence of Pop Culture on Society</td>\n",
       "      <td>Explore how popular culture trends influence f...</td>\n",
       "      <td>pop culture short popular culture refer collec...</td>\n",
       "      <td>[pop, culture, short, popular, culture, refer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In our fast-paced and hectic lives, we often f...</td>\n",
       "      <td>The Benefits of Mindful Eating</td>\n",
       "      <td>Learn how practicing mindful eating can improv...</td>\n",
       "      <td>fast pace hectic life find rush meal barely ta...</td>\n",
       "      <td>[fast, pace, hectic, life, find, rush, meal, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Financial literacy is a crucial skill that eve...</td>\n",
       "      <td>The Importance of Financial Literacy</td>\n",
       "      <td>Learn about the significance of understanding ...</td>\n",
       "      <td>financial literacy crucial skill possess refer...</td>\n",
       "      <td>[financial, literacy, crucial, skill, possess,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast fashion has become a dominant force in th...</td>\n",
       "      <td>The Impact of Fast Fashion on the Environment</td>\n",
       "      <td>Explore the environmental consequences of fast...</td>\n",
       "      <td>fast fashion dominant force clothing industry ...</td>\n",
       "      <td>[fast, fashion, dominant, force, clothing, ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical exercise has long been known to have ...</td>\n",
       "      <td>The Benefits of Regular Exercise for Mental He...</td>\n",
       "      <td>Learn how physical activity can improve mental...</td>\n",
       "      <td>physical exercise long know numerous benefit p...</td>\n",
       "      <td>[physical, exercise, long, know, numerous, ben...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Articolo  \\\n",
       "0  Pop culture, short for popular culture, refers...   \n",
       "1  In our fast-paced and hectic lives, we often f...   \n",
       "2  Financial literacy is a crucial skill that eve...   \n",
       "3  Fast fashion has become a dominant force in th...   \n",
       "4  Physical exercise has long been known to have ...   \n",
       "\n",
       "                                           Argomento  \\\n",
       "0            The Influence of Pop Culture on Society   \n",
       "1                     The Benefits of Mindful Eating   \n",
       "2               The Importance of Financial Literacy   \n",
       "3      The Impact of Fast Fashion on the Environment   \n",
       "4  The Benefits of Regular Exercise for Mental He...   \n",
       "\n",
       "                                         Descrizione  \\\n",
       "0  Explore how popular culture trends influence f...   \n",
       "1  Learn how practicing mindful eating can improv...   \n",
       "2  Learn about the significance of understanding ...   \n",
       "3  Explore the environmental consequences of fast...   \n",
       "4  Learn how physical activity can improve mental...   \n",
       "\n",
       "                              Articoli preprocessati  \\\n",
       "0  pop culture short popular culture refer collec...   \n",
       "1  fast pace hectic life find rush meal barely ta...   \n",
       "2  financial literacy crucial skill possess refer...   \n",
       "3  fast fashion dominant force clothing industry ...   \n",
       "4  physical exercise long know numerous benefit p...   \n",
       "\n",
       "                                     Articolo_tokens  \n",
       "0  [pop, culture, short, popular, culture, refer,...  \n",
       "1  [fast, pace, hectic, life, find, rush, meal, b...  \n",
       "2  [financial, literacy, crucial, skill, possess,...  \n",
       "3  [fast, fashion, dominant, force, clothing, ind...  \n",
       "4  [physical, exercise, long, know, numerous, ben...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione per LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Articolo_tokens'] = df['Articoli preprocessati'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(df['Articolo_tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['Articolo_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di topic: 50 -- Perplexity: -6.497904411234184 -- coherence: -1.8800947160206405\n",
      "Numero di topic: 51 -- Perplexity: -6.514393832877373 -- coherence: -1.6503354264066876\n",
      "Numero di topic: 52 -- Perplexity: -6.483584242264504 -- coherence: -1.343597367253222\n",
      "Numero di topic: 53 -- Perplexity: -6.4880426378636225 -- coherence: -1.8665981112291117\n",
      "Numero di topic: 54 -- Perplexity: -6.473018763758936 -- coherence: -1.9984422543490405\n",
      "Numero di topic: 55 -- Perplexity: -6.490004651062538 -- coherence: -2.0980427610969286\n",
      "Numero di topic: 56 -- Perplexity: -6.4969233344210595 -- coherence: -1.5586563899027455\n",
      "Numero di topic: 57 -- Perplexity: -6.51927615441179 -- coherence: -1.6447313405564186\n",
      "Numero di topic: 58 -- Perplexity: -6.527326547057778 -- coherence: -2.1582472238711103\n",
      "Numero di topic: 59 -- Perplexity: -6.505912263235901 -- coherence: -1.9790884889347797\n",
      "Numero di topic: 60 -- Perplexity: -6.499612311797471 -- coherence: -1.8741600860864331\n",
      "Numero di topic: 61 -- Perplexity: -6.513324556766129 -- coherence: -1.8654205638916168\n",
      "Numero di topic: 62 -- Perplexity: -6.522067353167496 -- coherence: -1.5030550460493164\n",
      "Numero di topic: 63 -- Perplexity: -6.502897299660251 -- coherence: -1.8892624720302276\n",
      "Numero di topic: 64 -- Perplexity: -6.509821708854069 -- coherence: -1.843133959357742\n",
      "Numero di topic: 65 -- Perplexity: -6.500313705201697 -- coherence: -1.6644839813560304\n",
      "Numero di topic: 66 -- Perplexity: -6.500343823453936 -- coherence: -2.0192347052136967\n",
      "Numero di topic: 67 -- Perplexity: -6.508413788944491 -- coherence: -1.9891649039605122\n",
      "Numero di topic: 68 -- Perplexity: -6.5397783825777775 -- coherence: -1.6713067621604263\n",
      "Numero di topic: 69 -- Perplexity: -6.531473824947353 -- coherence: -1.7874633924872811\n",
      "Numero di topic: 70 -- Perplexity: -6.525576044974404 -- coherence: -1.8872113416821013\n",
      "Numero di topic: 71 -- Perplexity: -6.514748623131221 -- coherence: -1.8646065795886213\n",
      "Numero di topic: 72 -- Perplexity: -6.543276709484981 -- coherence: -2.323061972251962\n",
      "Numero di topic: 73 -- Perplexity: -6.509464277012691 -- coherence: -1.788519129036438\n",
      "Numero di topic: 74 -- Perplexity: -6.556576993282878 -- coherence: -2.081915549753985\n",
      "Numero di topic: 75 -- Perplexity: -6.555782359754688 -- coherence: -1.8111777891693146\n",
      "Numero di topic: 76 -- Perplexity: -6.548174411611764 -- coherence: -1.496673744748819\n",
      "Numero di topic: 77 -- Perplexity: -6.5143580059196395 -- coherence: -1.9788648351295721\n",
      "Numero di topic: 78 -- Perplexity: -6.524188501445182 -- coherence: -1.9964788633010033\n",
      "Numero di topic: 79 -- Perplexity: -6.539807982409384 -- coherence: -1.730265903341456\n",
      "Numero di topic: 80 -- Perplexity: -6.520120091962712 -- coherence: -1.9547622250850256\n",
      "Numero di topic: 81 -- Perplexity: -6.549335995474239 -- coherence: -1.948976767766305\n",
      "Numero di topic: 82 -- Perplexity: -6.525642538387955 -- coherence: -2.0877428662481767\n",
      "Numero di topic: 83 -- Perplexity: -6.563465428146695 -- coherence: -2.0051092837309774\n",
      "Numero di topic: 84 -- Perplexity: -6.562032932257435 -- coherence: -1.8062325557978784\n",
      "Numero di topic: 85 -- Perplexity: -6.561688343747322 -- coherence: -1.9890895257779497\n",
      "Numero di topic: 86 -- Perplexity: -6.573514705324609 -- coherence: -1.8777406702995143\n",
      "Numero di topic: 87 -- Perplexity: -6.55438961639821 -- coherence: -1.9560143606870433\n",
      "Numero di topic: 88 -- Perplexity: -6.5309806841847236 -- coherence: -1.814211670617206\n",
      "Numero di topic: 89 -- Perplexity: -6.54195081137731 -- coherence: -1.7488013481656848\n",
      "Numero di topic: 90 -- Perplexity: -6.564563578862525 -- coherence: -2.1738671812982897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tiziano Pacifico\\Desktop\\Applicativi personali\\Test LDA,keybert,bertopic\\LDA.ipynb Cell 44\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tiziano%20Pacifico/Desktop/Applicativi%20personali/Test%20LDA%2Ckeybert%2Cbertopic/LDA.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m,\u001b[39m100\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tiziano%20Pacifico/Desktop/Applicativi%20personali/Test%20LDA%2Ckeybert%2Cbertopic/LDA.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     lda_model \u001b[39m=\u001b[39m LdaModel(corpus, num_topics\u001b[39m=\u001b[39;49mi, id2word\u001b[39m=\u001b[39;49mdictionary, passes\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tiziano%20Pacifico/Desktop/Applicativi%20personali/Test%20LDA%2Ckeybert%2Cbertopic/LDA.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     perplexity \u001b[39m=\u001b[39m lda_model\u001b[39m.\u001b[39mlog_perplexity(corpus)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tiziano%20Pacifico/Desktop/Applicativi%20personali/Test%20LDA%2Ckeybert%2Cbertopic/LDA.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     coherence_model_lda \u001b[39m=\u001b[39m CoherenceModel(model\u001b[39m=\u001b[39mlda_model, texts\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mArticolo_tokens\u001b[39m\u001b[39m'\u001b[39m], dictionary\u001b[39m=\u001b[39mdictionary, coherence\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mu_mass\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m use_numpy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    520\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(corpus, chunks_as_numpy\u001b[39m=\u001b[39;49muse_numpy)\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrained \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\ldamodel.py:1006\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1003\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPROGRESS: pass \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m, at document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1004\u001b[0m         pass_, chunk_no \u001b[39m*\u001b[39m chunksize \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[1;32m-> 1006\u001b[0m     gammat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_estep(chunk, other)\n\u001b[0;32m   1008\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimize_alpha:\n\u001b[0;32m   1009\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_alpha(gammat, rho())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\ldamodel.py:768\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    767\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n\u001b[1;32m--> 768\u001b[0m gamma, sstats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(chunk, collect_sstats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    769\u001b[0m state\u001b[39m.\u001b[39msstats \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sstats\n\u001b[0;32m    770\u001b[0m state\u001b[39m.\u001b[39mnumdocs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gamma\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]  \u001b[39m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\ldamodel.py:719\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    715\u001b[0m lastgamma \u001b[39m=\u001b[39m gammad\n\u001b[0;32m    716\u001b[0m \u001b[39m# We represent phi implicitly to save memory and time.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[39m# Substituting the value of the optimal phi back into\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[39m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[39;00m\n\u001b[1;32m--> 719\u001b[0m gammad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m expElogthetad \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mdot(cts \u001b[39m/\u001b[39;49m phinorm, expElogbetad\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m    720\u001b[0m Elogthetad \u001b[39m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m    721\u001b[0m expElogthetad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(Elogthetad)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "coherence_list = []\n",
    "for i in range(50,100):\n",
    "    lda_model = LdaModel(corpus, num_topics=i, id2word=dictionary, passes=20)\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['Articolo_tokens'], dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(f\"Numero di topic: {i} -- Perplexity: {perplexity} -- coherence: {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associo ogni id del topic alla lista delle parole chiave\n",
    "def match_topic_id_with_keywords(topic_id):\n",
    "    for topic in topics:\n",
    "        if topic[0]==topic_id:\n",
    "            return extract_words_from_topic(topic)\n",
    "    print(\"no match found\")\n",
    "    \n",
    "    def match_topic_id_lda_out(topic_id):\n",
    "    for topic in topics:\n",
    "        if topic[0]==topic_id:\n",
    "            return extract_out_from_topic(topic)\n",
    "    print(\"no match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=58, id2word=dictionary, passes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LDA keyword'] = df['LDA topic'].apply(match_topic_id_with_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LDA output'] = df['LDA topic'].apply(match_topic_id_lda_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\Applicativi personali\\\\Test LDA,keybert,bertopic\\\\Outputs\\\\\"\n",
    "filename = \"LDA_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(path+filename, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.048*\"influence\" + 0.044*\"celebrity\" + 0.026*\"trend\" + 0.025*\"society\" + 0.024*\"fashion\" + 0.024*\"opinion\" + 0.022*\"shape\" + 0.021*\"social\" + 0.020*\"public\" + 0.018*\"impact\"'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LDA output'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi10",
   "language": "python",
   "name": "p10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
