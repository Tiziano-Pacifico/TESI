{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90642a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ebdfb",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "Pur non essendo elevatissimo il numero delle submissions ottenute , considerando che la nostra ricerca si è spinta a ritroso fino all'apertura del canale, non potevamo avere una idea precisa del numero dei commenti per submissions. Ondo evitare di iniziare una singola e lunghissima operazione di estrazione dei commenti, che avrebbe comportato difficoltà qualora si fossero riscontrati problemi di connessione, eccezioni sollevate durante le chiamate delle api bug interni al codice si è quindi proceduto alla divisione dell'originale dataset in 74 tronconi di 1000 elementi ognuno (tranne l'ultimo ovviamente che sarà di dimensioni più ridotte).\n",
    "Questa scelta, pur aggiungendo overhead all'intera operazione di creazione del dataframe, ha permesso cmq di ottenere un maggior controllo sulle operazioni di estrazione, sul debugging e sulla sicurezza in generale della correttezza dei dati ottenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7082b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\TESI\\\\RedditDS\\\\df_submissions.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ece1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = []\n",
    "start = 0\n",
    "for end in range (1000, len(df), 1000):\n",
    "    list_df.append(df.iloc[start:end])\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10688640",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df.append(df.iloc[start:len(df)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411d122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df_submissions in enumerate(list_df):\n",
    "    df_submissions.to_json(f'C:\\\\Users\\\\Tiziano Pacifico\\\\Desktop\\\\TESI\\\\RedditDS\\\\\\splitted_df_sub\\\\splitted_df_sub{i+1}.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30220b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
